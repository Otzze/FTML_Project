{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a35458b3-e290-4d67-a3d7-11a41cb32ac4",
   "metadata": {},
   "source": [
    "# Exercise 2: Bayes Risk with absolute loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c47211-acd8-4c18-a164-e2fa27e902ba",
   "metadata": {},
   "source": [
    "## Question 0\n",
    "Let f be the following function:\n",
    "\n",
    "$\n",
    "f^* :\n",
    "\\begin{cases}\n",
    "\\mathcal{X} \\to \\mathcal{Y}\\\\\n",
    "x \\mapsto x^3\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "We can see that it has a zero derivative at $x=0$ but this point isn't a local extremum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba1bc08-4901-42e1-98cc-2fb2fabab8f2",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "For this question let's take the same supervised learning setting as the first exercise: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a35f58c0-645b-4742-8a09-a3efc13b4f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesured empirical risks with squared loss:\n",
      "Bayes: 2337430.0598996803\n",
      "F bar: 4539020.707325756\n",
      "--------------------------------------------\n",
      "Mesured empirical risks with absolute loss:\n",
      "F bar abs: 1609.640461514917\n",
      "Bayes: 1048.8806573790391\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "SAMPLE_SIZE = 1000\n",
    "\n",
    "# First we draw our input samples from the Poisson distribution\n",
    "X = np.random.poisson(lam=2, size=SAMPLE_SIZE)\n",
    "\n",
    "# Then Y is taken from the Gamma distribution with parameters X and 2000\n",
    "Y = np.where(X > 0, np.random.gamma(shape=X, scale=1000), 0.0)\n",
    "\n",
    "# Here we compute the predictions of the Bayes estimator\n",
    "Y_pred_Bayes = 1000 * X\n",
    "\n",
    "# Here we create the predictions of f bar\n",
    "Y_pred_f_bar = np.array([2000 for i in range(SAMPLE_SIZE)])\n",
    "\n",
    "# Now we can compute the empirical risks using the squared of both estimators\n",
    "Bayes_emp_risk = np.mean((Y_pred_Bayes - Y) ** 2).sum()\n",
    "f_bar_emp_risk = np.mean((Y_pred_f_bar - Y) ** 2).sum()\n",
    "\n",
    "# We also compute the empirical risks using the absolute loss\n",
    "f_bar_asb_risk = np.mean(np.abs(Y_pred_f_bar - Y)).sum()\n",
    "Bayes_abs_risk = np.mean(np.abs(Y_pred_Bayes - Y)).sum()\n",
    "\n",
    "print(\"Mesured empirical risks with squared loss:\")\n",
    "print(f\"Bayes: {Bayes_emp_risk}\")\n",
    "print(f\"F bar: {f_bar_emp_risk}\")\n",
    "print(\"--------------------------------------------\")\n",
    "print(\"Mesured empirical risks with absolute loss:\")\n",
    "print(f\"F bar abs: {f_bar_asb_risk}\")\n",
    "print(f\"Bayes: {Bayes_abs_risk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b23fb62-fee7-4f53-8c25-8405d11cf6c8",
   "metadata": {},
   "source": [
    "Here we can see that $R_{l_{absolute}} \\neq R_{l_{squared}}$ for both the Bayes estimator and $\\bar{f}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332daf02-946b-4391-94ac-43cf7f85634e",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "We want to find $f^*_{l_{absolute}}(x) = \\underset{z \\in \\mathbb{R}}{argmin}(\\mathbb{E}[|y-z|X=x])=\\underset{z \\in \\mathbb{R}}{argmin}(g(z))$\n",
    "\n",
    "with\n",
    "\n",
    "$g(z) = \\int_{y \\in \\mathbb{R}}|y - z|p_{Y|X=x}(y)dy$\n",
    "\n",
    "\\\n",
    "\\\n",
    "**1. Let's find the minimum of $g(z)$ by finding its derivative:**\n",
    "\n",
    "First, $g(z)$ is not differentiable at $y=z$, we split the integral at $y=z$:\n",
    "\n",
    "$g(z) = \\int_{-\\infty}^{z}|y - z|p_{Y|X=x}(y)dy + \\int_{z}^{+\\infty}|y - z|p_{Y|X=x}(y)dy$\n",
    "\n",
    "$g(z) = \\int_{-\\infty}^{z}(z - y)p_{Y|X=x}(y)dy + \\int_{z}^{+\\infty}(y - z)p_{Y|X=x}(y)dy$\n",
    "\n",
    "\\\n",
    "\\\n",
    "**2. Now we can compute the two derivatives:**\n",
    "\n",
    "- When $y < z$:\\\n",
    "    $\\frac{d}{dz}\\int_{-\\infty}^{z}(z - y)p_{Y|X=x}(y)dy = \\int_{-\\infty}^{z}p_{Y|X=x}(y)dy = F(z)$\n",
    "\n",
    "- When $y > z$:\\\n",
    "    $\\frac{d}{dz}\\int_{z}^{+\\infty}(y - z)p_{Y|X=x}(y)dy = -\\int_{z}^{+\\infty}p_{Y|X=x}(y)dy = -(1-F(z))$\n",
    "\n",
    "So adding the two gives:\n",
    "\n",
    "$g^{'}(z) = F(z)-(1-F(z))$\n",
    "\n",
    "\\\n",
    "\\\n",
    "**3. We find the extremum with the derivative:**\n",
    "\n",
    "If we need an extremum we have $g^{'}(x) = 0 \\implies F(z) = 1 - F(z) \\implies 2F(z) = 1 \\implies F(z) = \\frac{1}{2}$\n",
    "\n",
    "The derivative that cancels when $F(x) = \\frac{1}{2}$ means that z must be the median of conditional distribution of $Yâˆ£X=x$\n",
    "\n",
    "\\\n",
    "\\\n",
    "**4. Let's check that the solution we found is a minimum:**\n",
    "\n",
    "- When $y < median$: $g^{'}(x) < 0$\n",
    "- When $y > median$: $g^{'}(x) > 0$\n",
    "\n",
    "So we have found indeed a minimum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvim311",
   "language": "python",
   "name": "nvim311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
