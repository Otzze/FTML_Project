{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14c935b4-8b3c-4f28-acc2-5acd703b0b16",
   "metadata": {},
   "source": [
    "# Exercise 3: Statistical setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadc0a8d-1fe8-4081-8580-5758ca3836b3",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "We recall that the Bayes risk is the following:\n",
    "\n",
    "$\\mathbb{E}[\\mathcal{l}(f^*,y)]$ where $f^*$ is the Bayes estimator and $\\mathcal{l}$ is a loss function\n",
    "\n",
    "Let's take the squared loss function that is used in the OLS setting.\n",
    "\n",
    "$\\mathbb{E}_Y[\\mathcal{l}(f^*,y)]  = \\mathbb{E}[(y - f^*(X))^2]$\\\n",
    "$=\\mathbb{E}_\\epsilon[(X^T\\theta^* + \\epsilon - X^T\\theta^*)^2]$\\\n",
    "$=\\mathbb{E}_\\epsilon[\\epsilon^2]$\\\n",
    "$=\\sigma^2$\n",
    "\n",
    "And the Proposition 1 states that:\n",
    "\n",
    "$\\mathbb{E}[R_X(\\hat\\theta)] = \\frac{n - d}{n}\\sigma^2$\n",
    "\n",
    "So we can see that the Bayes risk is smaller that the OLS risk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6989b99c-0f5f-4290-b187-5370cede70de",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "$\\mathbb{E}[R_n(\\hat\\theta)] = \\mathbb{E}[\\frac{1}{n}||y - X \\hat \\theta||^2]$ \\\n",
    "$= \\mathbb{E}[\\frac{1}{n}||y - X(X^TX)^{-1}X^Ty||^2]$ \\\n",
    "$= \\mathbb{E}_\\epsilon[\\frac{1}{n}||X\\theta^* + \\epsilon - X(X^TX)^{-1}X^T(X\\theta^* + \\epsilon)||^2]$ \\\n",
    "$= \\mathbb{E}_\\epsilon[\\frac{1}{n}||(I_n - X(X^TX)^{-1}X^T)(X\\theta^* + \\epsilon)||^2]$\n",
    "\n",
    "Let $H=X(X^TX)^{-1}X^T$. We can see that $H$ is the projection matrix onto the subspace spanned by the columns of $X$ \\\n",
    "We can now deduce that $(I_n - H)X\\theta^* = X\\theta^* - HX\\theta^* = X\\theta^* - X\\theta^* = 0$\n",
    "\n",
    "So we have the final form of:\n",
    "\n",
    "$\\mathbb{E}[R_n(\\hat\\theta)] = \\mathbb{E}_\\epsilon[\\frac{1}{n}||(I_n - X(X^TX)^{-1}X^T)\\epsilon||^2]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2d6fa9-1f9f-41cf-8e24-b6ce465b9084",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Let $A \\in \\mathbb{R}^{n,n}$.\n",
    "\n",
    "$tr(A^TA)=\\sum_{i=1}^{n}(A^TA)_{ii} = \\sum_{i=1}^{n}\\sum_{j=1}^{n}A_{ij}^2 = \\sum_{(i,j \\in (1, n)^2)}A_{ij}^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6907047-2c73-45c9-b03e-8c797bc27424",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "$\\mathbb{E}_\\epsilon[\\frac{1}{n}||A\\epsilon||^2 = \\mathbb{E}_\\epsilon[\\frac{1}{n}\\sum_{(i,j \\in (1, n)^2)}A_{ij}^2\\epsilon^2]$ \\\n",
    "$= \\frac{1}{n}\\mathbb{E}_\\epsilon[\\epsilon^2]\\sum_{(i,j \\in (1, n)^2)}A_{ij}^2$\n",
    "$= \\frac{1}{n}\\mathbb{E}_\\epsilon[\\epsilon^2]tr(A^TA)$\n",
    "\n",
    "We know that $\\epsilon$ is a sample from a centered normal distribution of variance $\\sigma^2$ so $\\mathbb{E}_\\epsilon[\\epsilon^2]=\\sigma^2$\n",
    "\n",
    "We then have indeed:\n",
    "\n",
    "$\\mathbb{E}_\\epsilon[\\frac{1}{n}||A\\epsilon||^2 = \\frac{\\sigma^2}{n}tr(A^TA)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c25755d-7fd1-430d-9dfd-0c042191cdc7",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "Let $A = I_n - X(X^TX)^{-1}X^T$\n",
    "\n",
    "$A^TA = (I_n - X(X^TX)^{-1}X^T)^T(I_n - X(X^TX)^{-1}X^T)$ \\\n",
    "$= (I_n - X((X^TX)^{-1})^TX^T)(I_n - X(X^TX)^{-1}X^T)$ \\\n",
    "$= (I_n - X(X^TX)^{-1}X^T)(I_n - X(X^TX)^{-1}X^T)$ \\\n",
    "$= I_nI_n - I_nX(X^TX)^{-1}X^T - X(X^TX)^{-1}X^TI_n + (X(X^TX)^{-1}X^T)^2$ \\\n",
    "$= I_n - X(X^TX)^{-1}X^T - X(X^TX)^{-1}X^T + X(X^TX)^{-1}X^T$ \\\n",
    "$= I_n - X(X^TX)^{-1}X^T = A$\n",
    "\n",
    "So we have the equality $A^TA=A$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeb503e-bc63-45f5-a8b7-89f4fd849450",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "We know that:\n",
    "- $\\mathbb{E}[R_n(\\hat\\theta)] = \\mathbb{E}_\\epsilon[\\frac{1}{n}||(I_n - X(X^TX)^{-1}X^T)(X\\theta^* + \\epsilon)||^2]$\n",
    "- $\\mathbb{E}_\\epsilon[\\frac{1}{n}||(I_n - X(X^TX)^{-1}X^T)(X\\theta^* + \\epsilon)||^2] = \\mathbb{E}_\\epsilon[\\frac{1}{n}||A\\epsilon||^2$\n",
    "- $\\mathbb{E}_\\epsilon[\\frac{1}{n}||A\\epsilon||^2 = \\frac{\\sigma^2}{n}tr(A^TA)$\n",
    "\n",
    "So the we can deduce that $\\mathbb{E}[R_n(\\hat\\theta)] = \\frac{\\sigma^2}{n}tr(A^TA)$\n",
    "\n",
    "\\\n",
    "\\\n",
    "We also know that when $A = I_n - X(X^TX)^{-1}X^T$, then $A^TA=A$, so:\n",
    "\\\n",
    "\\\n",
    "$\\mathbb{E}[R_n(\\hat\\theta)] = \\frac{\\sigma^2}{n}tr(A)$\n",
    "\n",
    "\\\n",
    "finally,\n",
    "\n",
    "\\\n",
    "$tr(A) = tr(I_n - X(X^TX)^{-1}X^T) = tr(I_n) - tr(X(X^TX)^{-1}X^T)$\n",
    "\n",
    "\\\n",
    "We saw at question 2 that $I_n - X(X^TX)^{-1}X^T$ was the projection matrix onto the subspace spanned by the columns of $X$. Therefore,\n",
    "\n",
    "\n",
    "\\\n",
    "$tr(I_n) - tr(X(X^TX)^{-1}X^T) = n - d$\n",
    "\n",
    "And\n",
    "\n",
    "$\\mathbb{E}[R_n(\\hat\\theta)] = \\frac{n - d}{n}\\sigma^2$\n",
    "\n",
    "\\\n",
    "Thus proposition 1 is proven."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14caff3-9592-46f3-8213-82de30083700",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "\n",
    "We want to find:\n",
    "\n",
    "$\\mathbb{E}[\\frac{||y - X\\hat \\theta||^2_2}{n-d}]$\n",
    "\n",
    "Knowing:\n",
    "- $y = X\\theta^* + \\epsilon$\n",
    "- $\\hat \\theta = (X^TX)^{-1}X^Ty$\n",
    "\n",
    "$y - X\\hat \\theta = y - X(X^TX)^{-1}X^Ty$\\\n",
    "$= (I_n - X(X^TX)^{-1}X^T)y$\\\n",
    "$= Ay$\\\n",
    "$= A(X\\theta^* + \\epsilon)$\\\n",
    "$= AX\\theta^* + A\\epsilon$\n",
    "\n",
    "But\n",
    "\n",
    "$AX = (I_n - X(X^TX)^{-1}X^T)X$\\\n",
    "$= X - X(X^TX)^{-1}X^TX$ \\\n",
    "$= X - X$ \\\n",
    "$= 0$\n",
    "\n",
    "So\n",
    "\n",
    "$y - X\\hat \\theta = A\\epsilon$\n",
    "\n",
    "Now, from question 4, we can deduce $\\mathbb{E}[\\frac{||A\\epsilon||^2_2}{n-d}]$:\n",
    "\n",
    "$\\mathbb{E}[\\frac{||A\\epsilon||^2_2}{n-d}] = \\frac{\\sigma^2}{n-d}tr(A^TA)$ \\\n",
    "$= \\frac{\\sigma^2}{n-d}tr(A^TA)$ since $A^TA = A$ \\\n",
    "$= \\frac{\\sigma^2}{n-d}(n-d)$ from question 6 \\\n",
    "$= \\sigma^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6c2a28-7d22-442b-83e1-7a1e7639d8f4",
   "metadata": {},
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5324b3e-15fc-4e67-930c-38f1a3f39b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "   -Real sigma: 10\n",
      "   -Estimated sigma: 10.014766648109472\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "NB_SAMPLES = 10000\n",
    "SIGMA = 10\n",
    "NB_DIMENSIONS = 30\n",
    "\n",
    "\"\"\"\n",
    "This function computes the OLS estimator from X and y\n",
    "\"\"\"\n",
    "def compute_OLS(X, y):\n",
    "    XtX = X.T @ X\n",
    "    XtXm1 = np.linalg.inv(XtX)\n",
    "    return XtXm1 @ (X.T @ y)\n",
    "\n",
    "\"\"\"\n",
    "This function computes the output y from X and a variance sigma\n",
    "from the formula y = θ^* + ε\n",
    "\"\"\"\n",
    "def compute_y(X, theta_star, sigma):\n",
    "    return X @ theta_star + np.random.normal(0, sigma, size=NB_SAMPLES)\n",
    "\n",
    "\"\"\"\n",
    "First, we create the design matrix X.\n",
    "We take 1d samples to simplify the simulation\n",
    "\"\"\"\n",
    "X = np.random.uniform(low=0, high=1, size=(NB_SAMPLES, NB_DIMENSIONS))\n",
    "theta_star = np.random.uniform(low=0, high=1, size=NB_DIMENSIONS)\n",
    "\n",
    "\"\"\"\n",
    "We can now compute y and the OLS estimator\n",
    "\"\"\"\n",
    "y = compute_y(X, theta_star, SIGMA)\n",
    "OLS = compute_OLS(X, y)\n",
    "\n",
    "\"\"\"\n",
    "Let's compute the empirical risk of the OLS and thus the estimated sigma\n",
    "\"\"\"\n",
    "y_pred = X @ OLS\n",
    "emp_risk = ((y - y_pred)**2).sum() / NB_SAMPLES\n",
    "sigma_est = math.sqrt(emp_risk * NB_SAMPLES / (NB_SAMPLES - NB_DIMENSIONS))\n",
    "\n",
    "print(\"Results:\")\n",
    "print(f\"   -Real sigma: {SIGMA}\")\n",
    "print(f\"   -Estimated sigma: {sigma_est}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
